{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-elevation",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Install required packages and load relevant data.\n",
    "\n",
    "These functions derived from Roger's prepare data notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convinced-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy import stats\n",
    "from joblib import dump\n",
    "from src.data import make_dataset\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bearing-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path.cwd().parent\n",
    "report_dir = project_dir / 'reports'\n",
    "data_dir = project_dir / 'data'\n",
    "raw_data_dir = data_dir / 'raw'\n",
    "interim_data_dir = data_dir / 'interim'\n",
    "processed_data_dir = data_dir / 'processed'\n",
    "models_dir = project_dir / 'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-signal",
   "metadata": {},
   "source": [
    "## Download and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noble-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition = 'uts-advdsi-nba-career-prediction'\n",
    "make_dataset.download_data(competition=competition,\n",
    "                           path=raw_data_dir,\n",
    "                           unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "independent-scanner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TARGET_5Yrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6856.971000</td>\n",
       "      <td>7798.50000</td>\n",
       "      <td>62.777875</td>\n",
       "      <td>18.576662</td>\n",
       "      <td>7.267088</td>\n",
       "      <td>2.807037</td>\n",
       "      <td>6.231212</td>\n",
       "      <td>44.608900</td>\n",
       "      <td>0.264525</td>\n",
       "      <td>0.816562</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947788</td>\n",
       "      <td>71.365825</td>\n",
       "      <td>1.077838</td>\n",
       "      <td>2.168500</td>\n",
       "      <td>3.245300</td>\n",
       "      <td>1.624513</td>\n",
       "      <td>0.648687</td>\n",
       "      <td>0.245212</td>\n",
       "      <td>1.257763</td>\n",
       "      <td>0.833625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3977.447579</td>\n",
       "      <td>2309.54541</td>\n",
       "      <td>17.118774</td>\n",
       "      <td>8.935263</td>\n",
       "      <td>4.318732</td>\n",
       "      <td>1.693373</td>\n",
       "      <td>3.584559</td>\n",
       "      <td>6.155453</td>\n",
       "      <td>0.384093</td>\n",
       "      <td>1.060964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.252352</td>\n",
       "      <td>10.430447</td>\n",
       "      <td>0.785670</td>\n",
       "      <td>1.392224</td>\n",
       "      <td>2.085154</td>\n",
       "      <td>1.355986</td>\n",
       "      <td>0.407626</td>\n",
       "      <td>0.821037</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.372440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3799.00000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>-1.100000</td>\n",
       "      <td>-3.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-17.900000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3413.750000</td>\n",
       "      <td>5798.75000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6787.500000</td>\n",
       "      <td>7798.50000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10299.250000</td>\n",
       "      <td>9798.25000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>48.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13798.000000</td>\n",
       "      <td>11798.00000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>28.900000</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>168.900000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>12.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>18.900000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id_old           Id           GP          MIN          PTS  \\\n",
       "count   8000.000000   8000.00000  8000.000000  8000.000000  8000.000000   \n",
       "mean    6856.971000   7798.50000    62.777875    18.576662     7.267088   \n",
       "std     3977.447579   2309.54541    17.118774     8.935263     4.318732   \n",
       "min        4.000000   3799.00000    -8.000000     2.900000     0.800000   \n",
       "25%     3413.750000   5798.75000    51.000000    12.000000     4.100000   \n",
       "50%     6787.500000   7798.50000    63.000000    16.800000     6.300000   \n",
       "75%    10299.250000   9798.25000    74.000000    23.500000     9.500000   \n",
       "max    13798.000000  11798.00000   123.000000    73.800000    34.200000   \n",
       "\n",
       "               FGM          FGA          FG%      3P Made          3PA  ...  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  ...   \n",
       "mean      2.807037     6.231212    44.608900     0.264525     0.816562  ...   \n",
       "std       1.693373     3.584559     6.155453     0.384093     1.060964  ...   \n",
       "min       0.300000     0.800000    21.300000    -1.100000    -3.100000  ...   \n",
       "25%       1.600000     3.600000    40.400000     0.000000     0.100000  ...   \n",
       "50%       2.400000     5.400000    44.400000     0.300000     0.800000  ...   \n",
       "75%       3.700000     8.100000    48.700000     0.500000     1.500000  ...   \n",
       "max      13.100000    28.900000    67.200000     1.700000     4.700000  ...   \n",
       "\n",
       "               FTA          FT%         OREB         DREB          REB  \\\n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
       "mean      1.947788    71.365825     1.077838     2.168500     3.245300   \n",
       "std       1.252352    10.430447     0.785670     1.392224     2.085154   \n",
       "min       0.000000   -13.300000     0.000000     0.200000     0.300000   \n",
       "25%       1.000000    65.000000     0.500000     1.100000     1.700000   \n",
       "50%       1.700000    71.400000     0.900000     1.900000     2.800000   \n",
       "75%       2.600000    77.500000     1.500000     2.900000     4.300000   \n",
       "max      11.100000   168.900000     5.500000    11.000000    15.900000   \n",
       "\n",
       "               AST          STL          BLK          TOV  TARGET_5Yrs  \n",
       "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000  \n",
       "mean      1.624513     0.648687     0.245212     1.257763     0.833625  \n",
       "std       1.355986     0.407626     0.821037     0.723270     0.372440  \n",
       "min       0.000000     0.000000   -17.900000     0.100000     0.000000  \n",
       "25%       0.700000     0.300000     0.100000     0.700000     1.000000  \n",
       "50%       1.300000     0.600000     0.200000     1.100000     1.000000  \n",
       "75%       2.200000     0.900000     0.400000     1.600000     1.000000  \n",
       "max      12.800000     3.600000    18.900000     5.300000     1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(raw_data_dir / 'train.csv')\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outside-error",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id_old</th>\n",
       "      <th>Id</th>\n",
       "      <th>GP</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P Made</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>43.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8194</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>19.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>75.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.6</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>71.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8196</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>44.7</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>70.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8197</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>8175</td>\n",
       "      <td>3794</td>\n",
       "      <td>84</td>\n",
       "      <td>21.2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>50.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>68.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>8176</td>\n",
       "      <td>3795</td>\n",
       "      <td>49</td>\n",
       "      <td>16.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.6</td>\n",
       "      <td>44.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>50.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>8178</td>\n",
       "      <td>3796</td>\n",
       "      <td>53</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>43.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>8181</td>\n",
       "      <td>3797</td>\n",
       "      <td>89</td>\n",
       "      <td>38.3</td>\n",
       "      <td>14.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>45.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>89.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>8183</td>\n",
       "      <td>3798</td>\n",
       "      <td>55</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3799 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id_old    Id  GP   MIN   PTS  FGM   FGA   FG%  3P Made  3PA  ...  FTM  \\\n",
       "0          1     0  56   9.1   4.0  1.6   3.7  43.7      0.1  0.3  ...  0.7   \n",
       "1       8194     1  43  19.3  10.1  3.7   8.1  46.0      0.6  1.7  ...  1.8   \n",
       "2          3     2  82  33.9  11.3  4.9  10.6  45.6      0.5  1.9  ...  1.8   \n",
       "3       8196     3  86  44.7  18.8  6.8  15.9  42.9      0.5  1.8  ...  4.5   \n",
       "4       8197     4  58  12.3   4.7  1.6   4.0  40.0      0.5  1.7  ...  1.1   \n",
       "...      ...   ...  ..   ...   ...  ...   ...   ...      ...  ...  ...  ...   \n",
       "3794    8175  3794  84  21.2   8.7  3.4   6.7  50.2      0.0  0.0  ...  1.7   \n",
       "3795    8176  3795  49  16.3   6.4  2.9   6.6  44.4     -0.1 -0.4  ...  1.0   \n",
       "3796    8178  3796  53   9.9   2.1  0.8   1.8  43.1     -0.4 -0.6  ...  0.6   \n",
       "3797    8181  3797  89  38.3  14.5  5.4  11.8  45.2      0.5  1.2  ...  2.5   \n",
       "3798    8183  3798  55  12.0   3.0  1.1   2.5  42.3      0.1  0.6  ...  0.9   \n",
       "\n",
       "      FTA   FT%  OREB  DREB  REB  AST  STL  BLK  TOV  \n",
       "0     1.2  63.4   1.2   0.8  1.7  0.4  0.2  0.3  0.8  \n",
       "1     2.5  75.3   0.5   0.9  1.5  3.5  0.6  0.0  1.8  \n",
       "2     2.7  71.2   1.3   3.3  4.5  2.5  1.3  0.3  2.0  \n",
       "3     6.3  70.9   1.5   3.2  5.0  4.1  0.9  0.1  3.6  \n",
       "4     1.3  76.9   0.2   0.6  0.9  1.5  0.5 -0.4  0.9  \n",
       "...   ...   ...   ...   ...  ...  ...  ...  ...  ...  \n",
       "3794  2.5  68.1   1.9   2.3  3.9  1.5  0.6  0.3  2.0  \n",
       "3795  1.9  50.2   1.7   2.8  4.4  0.4  0.4  0.4  0.7  \n",
       "3796  1.0  63.9   0.7   1.0  1.7  0.4  0.4  0.2  0.5  \n",
       "3797  2.9  89.2   1.5   4.0  5.5  3.7  1.3  0.3  2.4  \n",
       "3798  1.1  76.7   0.7   2.0  2.6  0.6  0.3  0.2  1.2  \n",
       "\n",
       "[3799 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(raw_data_dir / 'test.csv')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "universal-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['Id_old', 'Id'], inplace=True)\n",
    "X_test.drop(columns=['Id_old'], inplace=True)\n",
    "test_id = X_test.pop('Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-ecology",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "TODO:\n",
    "* Linear model - exploratory first step\n",
    "* Consider PCA regression - Roger's PCA suggests high colinearity among predictors\n",
    "* Use random forest as a good out of the box tree method to handle colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "absolute-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'TARGET_5Yrs'\n",
    "X, y = make_dataset.separate_target(df_train, target=target)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-bolivia",
   "metadata": {},
   "source": [
    "### LogisticRegression\n",
    "\n",
    "This is a basic Random Forest with no parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "brazilian-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-fraction",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "radical-peninsula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('classifier',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=40, n_jobs=7,\n",
       "                   param_distributions={'classifier__class_weight': ['balanced'],\n",
       "                                        'classifier__penalty': ['l2', 'none'],\n",
       "                                        'pca__n_components': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1240d7358>},\n",
       "                   random_state=42, verbose=10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('classifier',LogisticRegression())\n",
    "])\n",
    "\n",
    "param_dist = {\n",
    "    'pca__n_components': stats.randint(1, X_train.shape[1]),\n",
    "    'classifier__penalty': ['l2','none'],\n",
    "    'classifier__class_weight': ['balanced']\n",
    "    \n",
    "}\n",
    "\n",
    "cv = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_dist,\n",
    "    random_state=42,\n",
    "    n_iter=40,\n",
    "    cv=10,\n",
    "    n_jobs=7,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "unlike-patent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__class_weight</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.451176</td>\n",
       "      <td>0.038487</td>\n",
       "      <td>0.029319</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.639444</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.258070</td>\n",
       "      <td>0.052814</td>\n",
       "      <td>0.021751</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.606944</td>\n",
       "      <td>0.633889</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208670</td>\n",
       "      <td>0.018190</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>7</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.631806</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.310107</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>0.026474</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>11</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>0.639861</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230650</td>\n",
       "      <td>0.031819</td>\n",
       "      <td>0.020961</td>\n",
       "      <td>0.010697</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.605556</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.601389</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.177611</td>\n",
       "      <td>0.038864</td>\n",
       "      <td>0.018015</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>0.581944</td>\n",
       "      <td>0.594444</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>0.586389</td>\n",
       "      <td>0.014643</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.155736</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.594444</td>\n",
       "      <td>0.609722</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>0.588333</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.236887</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>0.017063</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>12</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.181601</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>6</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.615278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623611</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.632083</td>\n",
       "      <td>0.014211</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.138145</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.015635</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.601389</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.570833</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.571528</td>\n",
       "      <td>0.020120</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.217542</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>0.019351</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>12</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.317384</td>\n",
       "      <td>0.040918</td>\n",
       "      <td>0.017808</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>17</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.665278</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.609722</td>\n",
       "      <td>0.642222</td>\n",
       "      <td>0.015605</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.205010</td>\n",
       "      <td>0.017749</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.291321</td>\n",
       "      <td>0.023290</td>\n",
       "      <td>0.015975</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>16</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.665278</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.609722</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.329597</td>\n",
       "      <td>0.026388</td>\n",
       "      <td>0.020163</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>15</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.639444</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.229882</td>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.017813</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>12</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.167112</td>\n",
       "      <td>0.016531</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>0.581944</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.177414</td>\n",
       "      <td>0.013214</td>\n",
       "      <td>0.019495</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>7</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.631806</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.176355</td>\n",
       "      <td>0.030339</td>\n",
       "      <td>0.018213</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>9</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.615278</td>\n",
       "      <td>0.641389</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.410229</td>\n",
       "      <td>0.041198</td>\n",
       "      <td>0.019345</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>18</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.642222</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.249419</td>\n",
       "      <td>0.022648</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>14</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.623611</td>\n",
       "      <td>0.642917</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.212272</td>\n",
       "      <td>0.022663</td>\n",
       "      <td>0.016709</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>9</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.615278</td>\n",
       "      <td>0.641389</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.180158</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.017465</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.594444</td>\n",
       "      <td>0.609722</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>0.588333</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.341014</td>\n",
       "      <td>0.025046</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>15</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.615278</td>\n",
       "      <td>0.639861</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.221066</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>0.026672</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>7</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>0.631806</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.227539</td>\n",
       "      <td>0.021756</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.606944</td>\n",
       "      <td>0.633889</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.193113</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.006902</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>0.581944</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.477450</td>\n",
       "      <td>0.106444</td>\n",
       "      <td>0.026197</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>17</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.642639</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.477168</td>\n",
       "      <td>0.077340</td>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.007844</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>18</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.640833</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.178286</td>\n",
       "      <td>0.013118</td>\n",
       "      <td>0.019714</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.605556</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.601389</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.203570</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>0.016555</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>6</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.615278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623611</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.632083</td>\n",
       "      <td>0.014211</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.224504</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.017124</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.441691</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>18</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.640833</td>\n",
       "      <td>0.016008</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.216233</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>12</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.661111</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.613889</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.201956</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.015738</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>0.640417</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.171101</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.605556</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.601389</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.277015</td>\n",
       "      <td>0.021252</td>\n",
       "      <td>0.018411</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>16</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.648611</td>\n",
       "      <td>0.665278</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.609722</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.188902</td>\n",
       "      <td>0.020048</td>\n",
       "      <td>0.030359</td>\n",
       "      <td>0.025805</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>8</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.606944</td>\n",
       "      <td>0.633889</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.205114</td>\n",
       "      <td>0.018307</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>balanced</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.630556</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.634722</td>\n",
       "      <td>0.606944</td>\n",
       "      <td>0.633889</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.262775</td>\n",
       "      <td>0.046328</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>balanced</td>\n",
       "      <td>l2</td>\n",
       "      <td>16</td>\n",
       "      <td>{'classifier__class_weight': 'balanced', 'clas...</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651389</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.665278</td>\n",
       "      <td>0.656944</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.609722</td>\n",
       "      <td>0.642222</td>\n",
       "      <td>0.016294</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.451176      0.038487         0.029319        0.009362   \n",
       "1        0.258070      0.052814         0.021751        0.003519   \n",
       "2        0.208670      0.018190         0.018968        0.006902   \n",
       "3        0.310107      0.016618         0.026474        0.015274   \n",
       "4        0.230650      0.031819         0.020961        0.010697   \n",
       "5        0.177611      0.038864         0.018015        0.010941   \n",
       "6        0.155736      0.014002         0.019119        0.006019   \n",
       "7        0.236887      0.015424         0.017063        0.006611   \n",
       "8        0.181601      0.012601         0.013738        0.004632   \n",
       "9        0.138145      0.030769         0.015635        0.005036   \n",
       "10       0.217542      0.022677         0.019351        0.008809   \n",
       "11       0.317384      0.040918         0.017808        0.006658   \n",
       "12       0.205010      0.017749         0.016809        0.005481   \n",
       "13       0.291321      0.023290         0.015975        0.007113   \n",
       "14       0.329597      0.026388         0.020163        0.008402   \n",
       "15       0.229882      0.039884         0.017813        0.005924   \n",
       "16       0.167112      0.016531         0.016657        0.002970   \n",
       "17       0.177414      0.013214         0.019495        0.008288   \n",
       "18       0.176355      0.030339         0.018213        0.006318   \n",
       "19       0.410229      0.041198         0.019345        0.011050   \n",
       "20       0.249419      0.022648         0.014462        0.003833   \n",
       "21       0.212272      0.022663         0.016709        0.005786   \n",
       "22       0.180158      0.013405         0.017465        0.009218   \n",
       "23       0.341014      0.025046         0.016895        0.005430   \n",
       "24       0.221066      0.015098         0.026672        0.010905   \n",
       "25       0.227539      0.021756         0.019783        0.002772   \n",
       "26       0.193113      0.033377         0.017360        0.006902   \n",
       "27       0.477450      0.106444         0.026197        0.011313   \n",
       "28       0.477168      0.077340         0.018474        0.007844   \n",
       "29       0.178286      0.013118         0.019714        0.005665   \n",
       "30       0.203570      0.007805         0.016555        0.006748   \n",
       "31       0.224504      0.011411         0.017124        0.009123   \n",
       "32       0.441691      0.024242         0.017544        0.006238   \n",
       "33       0.216233      0.017244         0.017911        0.009911   \n",
       "34       0.201956      0.021997         0.015738        0.005046   \n",
       "35       0.171101      0.016224         0.015286        0.004602   \n",
       "36       0.277015      0.021252         0.018411        0.009977   \n",
       "37       0.188902      0.020048         0.030359        0.025805   \n",
       "38       0.205114      0.018307         0.019394        0.009521   \n",
       "39       0.262775      0.046328         0.014038        0.005756   \n",
       "\n",
       "   param_classifier__class_weight param_classifier__penalty  \\\n",
       "0                        balanced                        l2   \n",
       "1                        balanced                        l2   \n",
       "2                        balanced                        l2   \n",
       "3                        balanced                      none   \n",
       "4                        balanced                        l2   \n",
       "5                        balanced                      none   \n",
       "6                        balanced                      none   \n",
       "7                        balanced                      none   \n",
       "8                        balanced                      none   \n",
       "9                        balanced                      none   \n",
       "10                       balanced                      none   \n",
       "11                       balanced                        l2   \n",
       "12                       balanced                        l2   \n",
       "13                       balanced                      none   \n",
       "14                       balanced                        l2   \n",
       "15                       balanced                      none   \n",
       "16                       balanced                        l2   \n",
       "17                       balanced                        l2   \n",
       "18                       balanced                        l2   \n",
       "19                       balanced                        l2   \n",
       "20                       balanced                      none   \n",
       "21                       balanced                      none   \n",
       "22                       balanced                      none   \n",
       "23                       balanced                      none   \n",
       "24                       balanced                      none   \n",
       "25                       balanced                      none   \n",
       "26                       balanced                        l2   \n",
       "27                       balanced                      none   \n",
       "28                       balanced                      none   \n",
       "29                       balanced                      none   \n",
       "30                       balanced                      none   \n",
       "31                       balanced                      none   \n",
       "32                       balanced                      none   \n",
       "33                       balanced                      none   \n",
       "34                       balanced                      none   \n",
       "35                       balanced                      none   \n",
       "36                       balanced                      none   \n",
       "37                       balanced                        l2   \n",
       "38                       balanced                      none   \n",
       "39                       balanced                        l2   \n",
       "\n",
       "   param_pca__n_components                                             params  \\\n",
       "0                       15  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "1                        8  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "2                        7  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "3                       11  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "4                        4  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "5                        3  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "6                        2  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "7                       12  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "8                        6  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "9                        1  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "10                      12  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "11                      17  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "12                      10  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "13                      16  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "14                      15  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "15                      12  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "16                       3  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "17                       7  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "18                       9  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "19                      18  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "20                      14  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "21                       9  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "22                       2  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "23                      15  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "24                       7  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "25                       8  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "26                       3  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "27                      17  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "28                      18  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "29                       4  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "30                       6  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "31                      10  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "32                      18  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "33                      12  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "34                      10  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "35                       4  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "36                      16  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "37                       8  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "38                       8  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "39                      16  {'classifier__class_weight': 'balanced', 'clas...   \n",
       "\n",
       "    split0_test_score  split1_test_score  ...  split3_test_score  \\\n",
       "0            0.644444           0.625000  ...           0.644444   \n",
       "1            0.630556           0.622222  ...           0.622222   \n",
       "2            0.631944           0.613889  ...           0.626389   \n",
       "3            0.633333           0.633333  ...           0.637500   \n",
       "4            0.605556           0.573611  ...           0.580556   \n",
       "5            0.602778           0.566667  ...           0.568056   \n",
       "6            0.602778           0.569444  ...           0.569444   \n",
       "7            0.654167           0.616667  ...           0.629167   \n",
       "8            0.631944           0.615278  ...           0.623611   \n",
       "9            0.601389           0.544444  ...           0.541667   \n",
       "10           0.654167           0.616667  ...           0.629167   \n",
       "11           0.641667           0.625000  ...           0.647222   \n",
       "12           0.634722           0.636111  ...           0.638889   \n",
       "13           0.641667           0.620833  ...           0.652778   \n",
       "14           0.644444           0.625000  ...           0.644444   \n",
       "15           0.654167           0.616667  ...           0.629167   \n",
       "16           0.602778           0.566667  ...           0.568056   \n",
       "17           0.631944           0.613889  ...           0.626389   \n",
       "18           0.641667           0.629167  ...           0.634722   \n",
       "19           0.650000           0.626389  ...           0.654167   \n",
       "20           0.659722           0.619444  ...           0.637500   \n",
       "21           0.641667           0.629167  ...           0.634722   \n",
       "22           0.602778           0.569444  ...           0.569444   \n",
       "23           0.644444           0.626389  ...           0.647222   \n",
       "24           0.631944           0.613889  ...           0.626389   \n",
       "25           0.630556           0.622222  ...           0.622222   \n",
       "26           0.602778           0.566667  ...           0.568056   \n",
       "27           0.641667           0.622222  ...           0.651389   \n",
       "28           0.644444           0.631944  ...           0.656944   \n",
       "29           0.605556           0.573611  ...           0.580556   \n",
       "30           0.631944           0.615278  ...           0.623611   \n",
       "31           0.634722           0.636111  ...           0.638889   \n",
       "32           0.644444           0.631944  ...           0.656944   \n",
       "33           0.654167           0.616667  ...           0.629167   \n",
       "34           0.634722           0.636111  ...           0.638889   \n",
       "35           0.605556           0.573611  ...           0.580556   \n",
       "36           0.641667           0.620833  ...           0.652778   \n",
       "37           0.630556           0.622222  ...           0.622222   \n",
       "38           0.630556           0.622222  ...           0.622222   \n",
       "39           0.641667           0.620833  ...           0.651389   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.651389           0.650000           0.651389   \n",
       "1            0.640278           0.640278           0.651389   \n",
       "2            0.636111           0.636111           0.656944   \n",
       "3            0.650000           0.648611           0.655556   \n",
       "4            0.590278           0.611111           0.616667   \n",
       "5            0.581944           0.594444           0.613889   \n",
       "6            0.591667           0.594444           0.609722   \n",
       "7            0.630556           0.647222           0.661111   \n",
       "8            0.637500           0.638889           0.656944   \n",
       "9            0.568056           0.573611           0.602778   \n",
       "10           0.630556           0.647222           0.661111   \n",
       "11           0.655556           0.647222           0.665278   \n",
       "12           0.647222           0.651389           0.655556   \n",
       "13           0.656944           0.648611           0.665278   \n",
       "14           0.651389           0.650000           0.651389   \n",
       "15           0.630556           0.647222           0.661111   \n",
       "16           0.581944           0.593056           0.612500   \n",
       "17           0.636111           0.636111           0.656944   \n",
       "18           0.652778           0.647222           0.655556   \n",
       "19           0.656944           0.640278           0.666667   \n",
       "20           0.645833           0.651389           0.659722   \n",
       "21           0.652778           0.647222           0.655556   \n",
       "22           0.591667           0.594444           0.609722   \n",
       "23           0.651389           0.648611           0.652778   \n",
       "24           0.636111           0.636111           0.656944   \n",
       "25           0.640278           0.640278           0.651389   \n",
       "26           0.581944           0.593056           0.612500   \n",
       "27           0.656944           0.648611           0.663889   \n",
       "28           0.651389           0.641667           0.666667   \n",
       "29           0.590278           0.611111           0.616667   \n",
       "30           0.637500           0.638889           0.656944   \n",
       "31           0.647222           0.651389           0.655556   \n",
       "32           0.651389           0.641667           0.666667   \n",
       "33           0.630556           0.647222           0.661111   \n",
       "34           0.647222           0.651389           0.655556   \n",
       "35           0.590278           0.611111           0.616667   \n",
       "36           0.656944           0.648611           0.665278   \n",
       "37           0.640278           0.640278           0.651389   \n",
       "38           0.640278           0.640278           0.651389   \n",
       "39           0.655556           0.647222           0.665278   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.652778           0.641667           0.613889         0.639444   \n",
       "1            0.652778           0.634722           0.606944         0.633889   \n",
       "2            0.655556           0.626389           0.608333         0.631806   \n",
       "3            0.650000           0.631944           0.620833         0.639861   \n",
       "4            0.601389           0.593056           0.576389         0.593750   \n",
       "5            0.597222           0.583333           0.573611         0.586389   \n",
       "6            0.593056           0.586111           0.579167         0.588333   \n",
       "7            0.659722           0.647222           0.613889         0.640417   \n",
       "8            0.654167           0.625000           0.612500         0.632083   \n",
       "9            0.588889           0.570833           0.566667         0.571528   \n",
       "10           0.659722           0.647222           0.613889         0.640417   \n",
       "11           0.656944           0.641667           0.609722         0.642222   \n",
       "12           0.650000           0.631944           0.619444         0.640417   \n",
       "13           0.658333           0.640278           0.609722         0.642500   \n",
       "14           0.652778           0.641667           0.613889         0.639444   \n",
       "15           0.659722           0.647222           0.613889         0.640417   \n",
       "16           0.597222           0.583333           0.573611         0.586111   \n",
       "17           0.655556           0.626389           0.608333         0.631806   \n",
       "18           0.651389           0.647222           0.615278         0.641389   \n",
       "19           0.651389           0.641667           0.612500         0.642222   \n",
       "20           0.654167           0.644444           0.623611         0.642917   \n",
       "21           0.651389           0.647222           0.615278         0.641389   \n",
       "22           0.593056           0.586111           0.579167         0.588333   \n",
       "23           0.652778           0.641667           0.615278         0.639861   \n",
       "24           0.655556           0.626389           0.608333         0.631806   \n",
       "25           0.652778           0.634722           0.606944         0.633889   \n",
       "26           0.597222           0.583333           0.573611         0.586111   \n",
       "27           0.658333           0.641667           0.611111         0.642639   \n",
       "28           0.647222           0.638889           0.612500         0.640833   \n",
       "29           0.601389           0.593056           0.576389         0.593750   \n",
       "30           0.654167           0.625000           0.612500         0.632083   \n",
       "31           0.650000           0.631944           0.619444         0.640417   \n",
       "32           0.647222           0.638889           0.612500         0.640833   \n",
       "33           0.659722           0.647222           0.613889         0.640417   \n",
       "34           0.650000           0.631944           0.619444         0.640417   \n",
       "35           0.601389           0.593056           0.576389         0.593750   \n",
       "36           0.658333           0.640278           0.609722         0.642500   \n",
       "37           0.652778           0.634722           0.606944         0.633889   \n",
       "38           0.652778           0.634722           0.606944         0.633889   \n",
       "39           0.656944           0.641667           0.609722         0.642222   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.013752               21  \n",
       "1         0.013296               23  \n",
       "2         0.014809               29  \n",
       "3         0.010245               19  \n",
       "4         0.013934               32  \n",
       "5         0.014643               37  \n",
       "6         0.012410               35  \n",
       "7         0.016095               12  \n",
       "8         0.014211               27  \n",
       "9         0.020120               40  \n",
       "10        0.016095               12  \n",
       "11        0.015605                5  \n",
       "12        0.010271               12  \n",
       "13        0.016773                3  \n",
       "14        0.013752               21  \n",
       "15        0.016095               12  \n",
       "16        0.014313               38  \n",
       "17        0.014809               29  \n",
       "18        0.011749                8  \n",
       "19        0.016247                5  \n",
       "20        0.013487                1  \n",
       "21        0.011749                8  \n",
       "22        0.012410               35  \n",
       "23        0.013722               19  \n",
       "24        0.014809               29  \n",
       "25        0.013296               23  \n",
       "26        0.014313               38  \n",
       "27        0.016042                2  \n",
       "28        0.016008               10  \n",
       "29        0.013934               32  \n",
       "30        0.014211               27  \n",
       "31        0.010271               12  \n",
       "32        0.016008               10  \n",
       "33        0.016095               12  \n",
       "34        0.010271               12  \n",
       "35        0.013934               32  \n",
       "36        0.016773                3  \n",
       "37        0.013296               23  \n",
       "38        0.013296               23  \n",
       "39        0.016294                5  \n",
       "\n",
       "[40 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "occupied-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cv.predict(X_val)\n",
    "probs = cv.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cooperative-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6769336734144793"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_val, probs[:, 1])\n",
    "roc_auc_score(y_val, probs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "varied-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 80,  36],\n",
       "       [226, 458]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(y_val))\n",
    "confusion_matrix(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "intense-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "artificial-verse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24.9k/24.9k [00:09<00:00, 2.59kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Successfully submitted to [UTS AdvDSI] NBA Career Prediction"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = cv.predict(X_test)\n",
    "pred_name = 'TARGET_5Yrs'\n",
    "pred_path = processed_data_dir / 'preds_rf_cv.csv'\n",
    "\n",
    "submission = pd.DataFrame({'id':test_id,'TARGET_5Yrs': preds})\n",
    "\n",
    "submission.to_csv(pred_path, index = False)\n",
    "\n",
    "api.competition_submit(file_name=pred_path,\n",
    "                       message=\"including randomised CV search\",\n",
    "                       competition=competition,\n",
    "                       quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-preparation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
